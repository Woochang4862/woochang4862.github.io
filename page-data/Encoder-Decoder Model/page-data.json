{"componentChunkName":"component---src-templates-post-jsx","path":"/Encoder-Decoder Model/","result":{"data":{"site":{"siteMetadata":{"title":"Woochang"}},"markdownRemark":{"id":"e39b99ae-1931-5474-b8ac-ef48fddbe6c8","excerpt":"Encoder-Decoder Model Seq2Seq Attention Transformer : Attention Is All You Need","html":"<h2>Encoder-Decoder Model</h2>\n<p><a href=\"Seq2Seq/\">Seq2Seq</a></p>\n<p><a href=\"Attention/\">Attention</a></p>\n<p><a href=\"Transformer%20Attention%20Is%20All%20You%20Need/\">Transformer : Attention Is All You Need</a></p>","frontmatter":{"title":"Encoder-Decoder Model","date":"June 27, 2022","update":"August 15, 2022","tags":["AI","Machine Learning","Data Science"],"series":"AI"},"fields":{"slug":"/Encoder-Decoder Model/","readingTime":{"minutes":0.06}}},"seriesList":{"edges":[{"node":{"id":"e39b99ae-1931-5474-b8ac-ef48fddbe6c8","fields":{"slug":"/Encoder-Decoder Model/"},"frontmatter":{"title":"Encoder-Decoder Model"}}}]},"previous":null,"next":{"fields":{"slug":"/Encoder-Decoder Model/Transformer Attention Is All You Need/"},"frontmatter":{"title":"Transformer : Attention Is All You Need"}}},"pageContext":{"id":"e39b99ae-1931-5474-b8ac-ef48fddbe6c8","series":"AI","previousPostId":null,"nextPostId":"1826848d-1d60-5036-bd93-a8f5d05a1aff"}},"staticQueryHashes":[]}